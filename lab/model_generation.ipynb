{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nlG_0Y4mJZL",
        "outputId": "be9e1332-2176-456a-f27d-f99443aa9856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ../model/fine_tuned_with_cs.zip\n",
            "   creating: llama3.2-3b-qlora-summary\n",
            "  inflating: llama3.2-3b-qlora-summary/README.md  \n",
            "   creating: llama3.2-3b-qlora-summary/checkpoint-100\n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-100/README.md  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-100/adapter_config.json  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-100/training_args.bin  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-100/special_tokens_map.json  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-100/tokenizer_config.json  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-100/rng_state.pth  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-100/trainer_state.json  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-100/chat_template.jinja  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-100/optimizer.pt  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-100/scheduler.pt  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-100/adapter_model.safetensors  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-100/tokenizer.json  \n",
            "  inflating: llama3.2-3b-qlora-summary/adapter_config.json  \n",
            "  inflating: llama3.2-3b-qlora-summary/training_args.bin  \n",
            "   creating: llama3.2-3b-qlora-summary/checkpoint-171\n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-171/README.md  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-171/adapter_config.json  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-171/training_args.bin  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-171/special_tokens_map.json  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-171/tokenizer_config.json  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-171/rng_state.pth  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-171/trainer_state.json  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-171/chat_template.jinja  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-171/optimizer.pt  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-171/scheduler.pt  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-171/adapter_model.safetensors  \n",
            "  inflating: llama3.2-3b-qlora-summary/checkpoint-171/tokenizer.json  \n",
            "  inflating: llama3.2-3b-qlora-summary/special_tokens_map.json  \n",
            "  inflating: llama3.2-3b-qlora-summary/tokenizer_config.json  \n",
            "  inflating: llama3.2-3b-qlora-summary/chat_template.jinja  \n",
            "  inflating: llama3.2-3b-qlora-summary/adapter_model.safetensors  \n",
            "  inflating: llama3.2-3b-qlora-summary/tokenizer.json  \n"
          ]
        }
      ],
      "source": [
        "!unzip ../model/fine_tuned_with_cs.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz6x3ul0m5-F"
      },
      "outputs": [],
      "source": [
        "!unzip final-summary.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e3k7193nCKs",
        "outputId": "f898ee81-aeb4-4296-e217-9c1fed547e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (2.3.3)\n",
            "Requirement already satisfied: datasets in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from pandas) (2.3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: requests>=2.32.2 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets) (2.32.5)\n",
            "Requirement already satisfied: httpx<1.0.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets) (0.70.18)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBUjeex7nC-l",
        "outputId": "0d4046cf-fa69-45d9-8744-05c825eecf64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8doJAbBgnEqG",
        "outputId": "36308a97-c6a1-492b-ddd6-13c882ab2a02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting xformers\n",
            "  Downloading xformers-0.0.33.post2.tar.gz (14.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting trl\n",
            "  Downloading trl-0.26.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting peft\n",
            "  Downloading peft-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.49.0-py3-none-macosx_14_0_arm64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=2.9 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from xformers) (2.9.1)\n",
            "Requirement already satisfied: numpy in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from xformers) (2.3.4)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from trl) (4.4.1)\n",
            "Requirement already satisfied: transformers>=4.56.1 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from trl) (4.57.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from peft) (25.0)\n",
            "Requirement already satisfied: psutil in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from peft) (7.1.3)\n",
            "Requirement already satisfied: pyyaml in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from peft) (6.0.3)\n",
            "Requirement already satisfied: tqdm in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: safetensors in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from peft) (0.7.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from peft) (0.36.0)\n",
            "Requirement already satisfied: filelock in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets>=3.0.0->trl) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets>=3.0.0->trl) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets>=3.0.0->trl) (0.4.0)\n",
            "Requirement already satisfied: pandas in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets>=3.0.0->trl) (2.3.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets>=3.0.0->trl) (2.32.5)\n",
            "Requirement already satisfied: httpx<1.0.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets>=3.0.0->trl) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets>=3.0.0->trl) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from datasets>=3.0.0->trl) (0.70.18)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.25.0->peft) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from torch>=2.9->xformers) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from torch>=2.9->xformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from torch>=2.9->xformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from torch>=2.9->xformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from transformers>=4.56.1->trl) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from transformers>=4.56.1->trl) (0.22.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (3.13.2)\n",
            "Requirement already satisfied: anyio in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (4.11.0)\n",
            "Requirement already satisfied: certifi in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (1.0.9)\n",
            "Requirement already satisfied: idna in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=3.0.0->trl) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.9->xformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from jinja2->torch>=2.9->xformers) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets>=3.0.0->trl) (1.3.1)\n",
            "Downloading trl-0.26.1-py3-none-any.whl (517 kB)\n",
            "Downloading peft-0.18.0-py3-none-any.whl (556 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
            "Downloading bitsandbytes-0.49.0-py3-none-macosx_14_0_arm64.whl (129 kB)\n",
            "Building wheels for collected packages: xformers\n",
            "  Building wheel for xformers (pyproject.toml) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for xformers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[247 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m /private/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/pip-build-env-lx2rtou5/overlay/lib/python3.13/site-packages/torch/_subclasses/functional_tensor.py:279: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  \u001b[31m   \u001b[0m   cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
            "  \u001b[31m   \u001b[0m /private/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/pip-build-env-lx2rtou5/overlay/lib/python3.13/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "  \u001b[31m   \u001b[0m !!\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
            "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         License :: OSI Approved :: BSD License\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m !!\n",
            "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\n",
            "  \u001b[31m   \u001b[0m running bdist_wheel\n",
            "  \u001b[31m   \u001b[0m W1218 15:55:44.269000 5646 torch/utils/cpp_extension.py:630] Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  \u001b[31m   \u001b[0m running build\n",
            "  \u001b[31m   \u001b[0m running build_py\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/_deprecation_warning.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/attn_bias_utils.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/checkpoint.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/test.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/utils.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/_cpp_lib.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/fwbw_overlap.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/info.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/triton/importing.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/triton/vararg_kernel.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/triton/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/triton\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/flash_attn_3\n",
            "  \u001b[31m   \u001b[0m copying xformers/flash_attn_3/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/flash_attn_3\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/components\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/residual.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/components\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/components\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/input_projection.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/components\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_mem_eff_attention.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_indexing.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_revnet.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_swiglu.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_merge_attentions.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_tiled_matmul.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/utils.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_nystrom_utils.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_attn_decoding.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sequence_parallel_fused.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sddmm.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sp24.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_core.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/rmsnorm.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/modpar_layers.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/swiglu_op.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/unbind.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/rope_padded.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/seqpar.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/sequence_parallel_fused_ops.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/sp24.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/tree_attention.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/common.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/differentiable_collectives.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/tiled_matmul.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/indexing.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/device_limits.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/find_slowest.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler_dcgm_impl.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler_dcgm.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/api.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/profile_analyzer.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/sparse\n",
            "  \u001b[31m   \u001b[0m copying xformers/sparse/_csr_ops.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/sparse\n",
            "  \u001b[31m   \u001b[0m copying xformers/sparse/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/sparse\n",
            "  \u001b[31m   \u001b[0m copying xformers/sparse/utils.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/sparse\n",
            "  \u001b[31m   \u001b[0m copying xformers/sparse/blocksparse_tensor.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/sparse\n",
            "  \u001b[31m   \u001b[0m copying xformers/sparse/csr_tensor.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/sparse\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_blocksparse_attn_interface.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_blocksparse_attention.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/bert_padding.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_og.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_interface.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/_sputnik_sparse.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/core.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/fourier_mix.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/scaled_dot_product.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/utils.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/attention_mask.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/attention_patterns.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/sparsity_config.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/base.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks/LRA\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/batch_submit.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks/LRA\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/batch_fetch_results.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks/LRA\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_with_submitit.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks/LRA\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks/LRA\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_tasks.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks/LRA\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_grid_search.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks/LRA\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks/LRA/code\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks/LRA/code\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/model_wrapper.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks/LRA/code\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/dataset.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/benchmarks/LRA/code\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/k_scaled_index_add.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/matmul_perf_model.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/rope_padded_kernels.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/tiled_matmul_kernels.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/k_index_select_cat.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/rmsnorm_kernels.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/cutlass_blackwell.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/flash3.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/dispatch.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/attn_bias.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/ck.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/common.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/torch_attention_compat.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/flash.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/cutlass.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/merge_training.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/ck_splitk.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/triton_splitk.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/_triton/splitk_kernels.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/_triton/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/ops/fmha/_triton\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/losses\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/losses/cross_entropy.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/losses\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/losses/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/losses\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/mask.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/seqlen_info.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/ampere_helpers.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/flash_bwd.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/blackwell_helpers.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/benchmark_mask_mod.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/benchmark.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/block_sparsity.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/pack_gqa.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/flash_bwd_sm90.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/barrier.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/flash_bwd_postprocess.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/flash_bwd_sm100.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/interface.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/named_barrier.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/copy_utils.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/hopper_helpers.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/flash_fwd.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/cute_dsl_utils.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/utils.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/pipeline.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/mask_definitions.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/block_info.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/flash_fwd_sm100.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/flash_bwd_preprocess.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/flash_fwd_combine.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/mma_sm100_desc.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/testing.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/tile_scheduler.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/softmax.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/cute/fast_math.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/cute\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/layers\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/layers\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/patch_embed.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/layers\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/rotary.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/layers\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_prefill_split.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_ref.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fp8.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_prefill.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/interface_fa.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_prefill_onekernel.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/test.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bench.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_prefill.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/utils.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/train.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_decode.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_ref.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_prefill_fused.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/pretrained.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/generation.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/library.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/benchmark.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/distributed.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/testing.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/torch.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/bigcode.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gptj.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/opt.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/llama.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/vit.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/btlm.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/baichuan.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/bert.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/falcon.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gpt_neox.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gpt.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/activations.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/fused_dense.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/rms_norm.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/layer_norm.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/ops\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/modules\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/embedding.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/modules\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/modules\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/mlp.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/modules\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/block.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/modules\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/mha.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/modules\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/cross_entropy.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/linear.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/k_activations.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/__init__.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/mlp.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/rotary.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/layer_norm.py -> build/lib.macosx-15.0-arm64-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m running build_ext\n",
            "  \u001b[31m   \u001b[0m building 'xformers._C' extension\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-15.0-arm64-cpython-313/xformers/csrc/attention\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-15.0-arm64-cpython-313/xformers/csrc/attention/autograd\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-15.0-arm64-cpython-313/xformers/csrc/attention/cpu\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-15.0-arm64-cpython-313/xformers/csrc/sparse24\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-15.0-arm64-cpython-313/xformers/csrc/swiglu\n",
            "  \u001b[31m   \u001b[0m clang++ -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -I/private/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/pip-install-25v5tyj1/xformers_ae7d3990971c464fa2ee5e4840302d3f/xformers/csrc -I/private/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/pip-build-env-lx2rtou5/overlay/lib/python3.13/site-packages/torch/include -I/private/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/pip-build-env-lx2rtou5/overlay/lib/python3.13/site-packages/torch/include/torch/csrc/api/include \"-I/Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/include\" -I/opt/homebrew/opt/python@3.13/Frameworks/Python.framework/Versions/3.13/include/python3.13 -c xformers/csrc/attention/attention.cpp -o build/temp.macosx-15.0-arm64-cpython-313/xformers/csrc/attention/attention.o -O3 -std=c++17 -DPy_LIMITED_API=0x03090000 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPy_LIMITED_API=0x03090000 -DTORCH_EXTENSION_NAME=_C\n",
            "  \u001b[31m   \u001b[0m clang++: error: unsupported option '-fopenmp'\n",
            "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang++' failed with exit code 1\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for xformers\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build xformers\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (xformers)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install xformers trl peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7WR1sJS1nF6D"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
        "import torch\n",
        "from gc import collect\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRrDs_f6na6D",
        "outputId": "b283669c-a36d-4614-f852-27654d0e6ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We would be using this device: mps\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(\"We would be using this device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeIfjgbnnd1R",
        "outputId": "4113f797-93ee-4369-c6c4-59e3e0949c9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "2-[1/8] Loading dataset...\n",
            "✓ Loaded 101 examples\n"
          ]
        }
      ],
      "source": [
        "# Load JSONL data (Custom Dataset)\n",
        "print(\"\\n2-[1/8] Loading dataset...\")\n",
        "data = []\n",
        "with open(\"../data/custom_dataset.jsonl\", \"r\") as f:\n",
        "    for line in f:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "custom_dataset = Dataset.from_dict({\n",
        "    \"messages\": [item[\"messages\"] for item in data]\n",
        "})\n",
        "split_dataset = custom_dataset.train_test_split(test_size=0.1, seed=42)\n",
        "val_dataset = split_dataset[\"test\"]\n",
        "\n",
        "print(f\"✓ Loaded {len(val_dataset)} examples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H5kxtmdUnl32"
      },
      "outputs": [],
      "source": [
        "def extract_msg_for_base_model(_msg):\n",
        "    messages = _msg[\"messages\"]\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"You are an AI assistant that helps provide the summary for a youtube video given we provide you with a user search text, and based on the search text youtube has given out 4 relevant videos as a result, we will give you the search text, video title and the transcript of all the result videos (it could be between 1 to 4 ), your job is to summarize the video according to the prompt and also address the similarities and differences in the video's opinion over the user's query.\n",
        "\n",
        "for example:\n",
        "\n",
        "SEARCH_TEXT: Whats the Best thing to do on Holidays\n",
        "\n",
        "VIDEO_1_TITLE: Top 5 things to do on Holidays\n",
        "VIDEO_1_TRANSCRIPT: One of the Thing to do on Holiday is to visit your grandparents and spend some time with your family....\n",
        "\n",
        "VIDEO_2_TITLE: Top 5 Games to try on Holidays\n",
        "VIDEO_2_TRANSCRIPT: Well you can try Death Stranding or Far Cry (Entire Series) so that u have time to play and also see how they grow over time and you won't see how time passes so quickly...\n",
        "\n",
        "VIDEO_3_TITLE: How to Convince your boss to work on Holidays\n",
        "VIDEO_3_TRANSCRIPT: Tells ways to work on Holidays instead of Enjoying...\n",
        "\n",
        "I am expecting Output like...\n",
        "\n",
        "Key points from Video_1:\n",
        "...\n",
        "\n",
        "Key points from Video_2:\n",
        "...\n",
        "\n",
        "Transcript 2 unpacked:\n",
        "...\n",
        "\n",
        "well Video 1 and Video 2 agree on the fact that you should spend some time in leisure during holiday be it playing games or with your family. Video 1 seems to be giving good advice and Suggestions from Video 2 can also be considered if you are into games, while Video 3 out of no where suggesting things that might not be average thing to do on Holidays, it focuses more on Working than Enjoying as opposed to  other videos\n",
        "\n",
        "\n",
        "That's the Example, please make sure to follow these rules as well.\n",
        "- No bullet points, no lists, no headings.\n",
        "- Do not use any characters that cannot be typed directly on a standard keyboard, including but not limited to em-dashes (-), en-dashes (-), smart quotes (\" \", ' '), or any other special typographic symbols. Use only standard ASCII characters.\n",
        "- You may also compare videos, for example: \"video 1 is similar to video 2 except for this part where they disagree\", or \"video 3 is more similar to video 1 where the speakers have the same views on this...\".\n",
        "- Combine the relevant points from the transcripts into smooth, continuous paragraph(s) for each video.\n",
        "- Ignore irrelevant or repeated transcript content.\n",
        "- Tone should be clear, helpful, and natural.\n",
        "- Always reference videos by their index like VIDEO_1, VIDEO_2.\n",
        "- For each video, write a short section summarizing only the key insights. Keep it 3–5 sentences or around 50–100 words.\n",
        "\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": messages[1][\"content\"]\n",
        "            }\n",
        "        ]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a2fa305397f94b2db05f1cfc254c913d",
            "6492b6fb63e4484c9adee33ddb75ec71",
            "f5ed6a170fac437f9232c30375ecba13",
            "a681a02a089a4f31bf5e78d308f38002",
            "3c51563cf9b7417f96660494a64abfa0",
            "f0b005a41da34a11829f12ab9e1ebe5b",
            "4c54b01ebe8c407ab992310df2895176",
            "ad47f594d4b74a96ac783e88dad964b9",
            "13ea083a6c5d45c891984a0a73759a6d",
            "dcc20ff8befa426387a4a2c59a0169a7",
            "0f4a154bf65e4b59a5e369083df2cef5"
          ]
        },
        "id": "luCjvuLNnuan",
        "outputId": "0811b497-4cad-4c4e-ed12-3d10ef21cb45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 101/101 [00:00<00:00, 5733.72 examples/s]\n"
          ]
        }
      ],
      "source": [
        "base_generation_inputs = val_dataset.map(extract_msg_for_base_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "err3vImBnwE-"
      },
      "outputs": [],
      "source": [
        "BASE_MODEL = \"meta-llama/Llama-3.2-3B-Instruct\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xigzAQ5inz3_"
      },
      "outputs": [],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_8bit=True,\n",
        "        bnb_8bit_compute_dtype=torch.bfloat16,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o22n7Z60oIa6",
        "outputId": "9676a645-fcac-4412-a347-eaea3cab999b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): ^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/bin/huggingface-cli\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 61, in main\n",
            "    service.run()\n",
            "  File \"/Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/commands/user.py\", line 113, in run\n",
            "    login(\n",
            "  File \"/Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_deprecation.py\", line 31, in inner_f\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/_login.py\", line 124, in login\n",
            "    interpreter_login(new_session=new_session)\n",
            "  File \"/Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_deprecation.py\", line 31, in inner_f\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/_login.py\", line 281, in interpreter_login\n",
            "    token = getpass(\"Enter your token (input will not be visible): \")\n",
            "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/getpass.py\", line 76, in unix_getpass\n",
            "    passwd = _raw_input(prompt, stream, input=input)\n",
            "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/getpass.py\", line 146, in _raw_input\n",
            "    line = input.readline()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393,
          "referenced_widgets": [
            "60cdf53a72304a458ae66faed8b3d4f5",
            "3771e7d855f64f7f94fd961f55716d26",
            "490465d310a849479efb022b418c9c93",
            "32329bf24cbe4181aa4a8a21182c48d5",
            "1101c414c8a54e2d99cf491599c853d8",
            "3bb8a9ed4dae48f295102a600bb65e9a",
            "5776ddb2ba1748b5be5347476e73c5cf",
            "b59e7a392ca14ec8a4a88839c98e95db",
            "682c4817bc91424a969c7cfda695f543",
            "aaafdbfb57ed46d5992cd2939131b274",
            "71c710b347794ab48e9d57e0ef6fdef1",
            "98fa080856bb49ff86039b70465aab14",
            "0cd4870d05b74647ab36181be56729c3",
            "bf5a481b37854f64aeab6ca042a94da4",
            "0795e6dc22c94d958541354b9eb211ad",
            "bc0c72356941423f8bbf0056a948938c",
            "b1417a3ea7b9417e8480570e360f9f48",
            "300d1300846b485990a3538d4fa456fc",
            "adc238511f564740a0f1788d107a4d94",
            "6255e3b5877749289017ab00a9202319",
            "06365b5aafda4a61806d483de923ca4a",
            "10debec83cbe443b9b5e778ebb06bc27",
            "14ff1e39878c4a0a902aaa7ba15be878",
            "06c526461b3c439d81e9f4b1a67bef89",
            "4d00c63398a3496e9faa2246b2c32541",
            "78b2b4581bc940348ba1f0b21a997b77",
            "eb57fc4b0be1401abc7d6867a6849795",
            "dd68af5b3a1a4cd2a3d2e51831eb1e3f",
            "3f14f6a5af6d45a5981d24df424ee151",
            "e2ebd9f83bc44ba5ad6dc02626bf3e6f",
            "0d3cdca63fa5417e8a2cefdc809b4c3e",
            "7371ba4c17b948d6859a89e899050601",
            "3792c7d80cd042caa861237e5a5a7f88",
            "e4367ad58be841148987f12b964a32f6",
            "393ad97c931e449a91e104e85783fe66",
            "6d79c59696da4eb290e5febcaadfcb66",
            "0855ac647c51420897207bd9837d2298",
            "7e3dc80f38fe4b9e90c56633eceed6f2",
            "1f845e30f64e4d7ea65fa8caf2f892d5",
            "1c64423283e14d3d8b0aba94f70415ba",
            "c3031da0e4574822a1d45dedb927ce67",
            "ff9fe16a51934b2b9fc50fafbbad9ce1",
            "9b5ebf399f624b13b15de735887a015e",
            "c0d352944469475cbde6f3555e6c6277",
            "fb0d6d199b124f02b4254e22c4b73f80",
            "77abae2bf7bd4d7999094ee2c5fc4e67",
            "d901177d164e400aaf61467de19ca671",
            "50ba1f15232d465facd6e3f43a6626cf",
            "4c9cb58826364bc58c0bc7fb9a34af9d",
            "5f2461130b4a4469bc5f19c6a0d772b1",
            "bf165ae12dcb4b5992a0c3419a0ae230",
            "e7a34773567a451889503283f50f39e1",
            "a71a6564eef34ef39242065500f89c4f",
            "4c37f59d45a7487aa0ce3c8fbe6ac038",
            "225efe0dc6dc4e69a22903abafe3afd8",
            "428dfe8a63ea4fa387f753e38ad013a5",
            "7a56280bccfc4776a2e83a6308034eeb",
            "229f9bac145e432eac3dcc9e0baa5d28",
            "2fd49de4d17841f28842856ba878d3c5",
            "444c25a1af534fda89afbe56c392ca56",
            "83780244380c4b5abfe605e4a7389a23",
            "438ff1b810f743b4b9656f84c5cc5914",
            "6eb48d8dca3b4f8baa6a181f599af4c6",
            "5e4a6aa9039741f698e46cdfe287a16e",
            "4eea3a7d14544be8b5dbdb255dedbded",
            "eae485e90e94418c9703bbae5cff6d95",
            "59dbf2b961c44edfbae4256d83bb1708",
            "cea44ec8331a4058bceef660bf396cf8",
            "152e939ee063490aa640feb59eddb545",
            "677966dddd8b4096a0b7251366fae938",
            "ed5a780960de43ec80a46344e722b35c",
            "a38a3c44c26747df8f54020a4c32eaf5",
            "4ff8bbe0699749ec9aa91f9a8a0f0032",
            "336350b3227a4fb6b5678950ae02308a",
            "61d6cce34867420098b1888865ccdac4",
            "a72bb69172374850a5eb4450f3ac9f99",
            "055d3b192def41ccace818bc2c8b2684",
            "5de3b4d0027c4b57aafcab69eff64218",
            "858b1a1e25174b8398cf1f7def4c74e0",
            "a776a2d4181e46a693da3d7367e8baf6",
            "bc36d005b7584ca2acee5be5ffb2cef3",
            "08428c6e4d104fd08ea762af7b347b49",
            "6ef970331a554a519e42d46522fefdb7",
            "2f5ad3b92e2442f3a6ddd53cb1be1893",
            "c3276a231d324137a409a35908de7024",
            "ab32170ca7c74c048c724f3a80bf9a8c",
            "c86207436901472986282893210c173c",
            "bff9f53bef434e8488917d18f42680f3",
            "e448d97be72b4f16b49946e373097222",
            "70efee92eccf4f63b11acc9200f8351d",
            "09202c003d074ef2b985902c8690391b",
            "1301f17e37da4320aac7917c9553756e",
            "28de7fa0443647d39b3f9a6712f53a1e",
            "fca4bdd0991c4adca567d768c46f5ca7",
            "eac6e7a4232c464cbd251a37aeecaa72",
            "5a245a2bc5014dd5a0e0fbdce4c61dce",
            "827ac0be3728424582e83e2fc1d31008",
            "9d3c690292c940ea805e27ec9943df59",
            "da3e442144c947508cbb7c2d2993500b",
            "c4c90a495abf46028ec72e9954541815",
            "b4ace38457ec484fa10b0e62e5baa84f",
            "80ef48534d264ba897dc320d92aef3e9",
            "aba419aeb82b467c88780412a300cfba",
            "7a88f81d22d3448f852f6d9f6cf74348",
            "2f060c6ab72b44daa864e3f1e2fbeda9",
            "ae3eb50f0ebf455e9b76b33d6692c207",
            "738a193bfd99452a874eeb1a910569b6",
            "5ec8c8c2b368402fa1cf6b8537436a77",
            "6c3c63491bf8448abece39eb428a52f0",
            "1dd9be2b4ad44655b138ea0ee6a78027"
          ]
        },
        "id": "Gix46p4fn827",
        "outputId": "9b5b1930-e539-4aaf-ca49-2e94fe6c34c1"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m base_tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m        \u001b[49m\u001b[43mBASE_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# LLaMA models usually do not have a pad token by default\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m base_tokenizer.pad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py:1156\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1152\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1153\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1154\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist or is not currently imported.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1155\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[32m   1159\u001b[39m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[32m   1160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:2076\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[39m\n\u001b[32m   2074\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2075\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2076\u001b[39m         resolved_vocab_files[file_id] = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2077\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2078\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2079\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2080\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2081\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2082\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2083\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2084\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2085\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2086\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2087\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2088\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2089\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2090\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2091\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   2092\u001b[39m         \u001b[38;5;66;03m# Re-raise any error raised by cached_file in order to get a helpful error message\u001b[39;00m\n\u001b[32m   2093\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/transformers/utils/hub.py:322\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    265\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    266\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    267\u001b[39m     **kwargs,\n\u001b[32m    268\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    269\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    271\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/transformers/utils/hub.py:479\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    478\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    494\u001b[39m         snapshot_download(\n\u001b[32m    495\u001b[39m             path_or_repo_id,\n\u001b[32m    496\u001b[39m             allow_patterns=full_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    505\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    506\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:1007\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    987\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    988\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    989\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1004\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1005\u001b[39m     )\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:1168\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1180\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n\u001b[32m   1181\u001b[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:1735\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[39m\n\u001b[32m   1728\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants.HF_HUB_DISABLE_XET:\n\u001b[32m   1729\u001b[39m             logger.warning(\n\u001b[32m   1730\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo, but the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhf_xet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m package is not installed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1731\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFalling back to regular HTTP download. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1732\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFor better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1733\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1735\u001b[39m         \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1736\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1737\u001b[39m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1738\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1739\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1740\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1741\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1742\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1745\u001b[39m _chmod_and_move(incomplete_path, destination_path)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:423\u001b[39m, in \u001b[36mhttp_get\u001b[39m\u001b[34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[39m\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    418\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    419\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe file is too large to be downloaded using the regular download method. Use `hf_transfer` or `hf_xet` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    420\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Try `pip install hf_transfer` or `pip install hf_xet`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    421\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHF_HUB_DOWNLOAD_TIMEOUT\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    427\u001b[39m hf_raise_for_status(r)\n\u001b[32m    428\u001b[39m total: Optional[\u001b[38;5;28mint\u001b[39m] = _get_file_length_from_http_response(r)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:306\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    305\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m response = \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m hf_raise_for_status(response)\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:306\u001b[39m, in \u001b[36mhttp_backoff\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[39m\n\u001b[32m    303\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m].seek(io_obj_initial_pos)\n\u001b[32m    305\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m response = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n\u001b[32m    308\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:95\u001b[39m, in \u001b[36mUniqueRequestIdAdapter.send\u001b[39m\u001b[34m(self, request, *args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     97\u001b[39m     request_id = request.headers.get(X_AMZN_TRACE_ID)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1430\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "base_tokenizer = AutoTokenizer.from_pretrained(\n",
        "        BASE_MODEL,\n",
        "        use_fast=True\n",
        "    )\n",
        "# LLaMA models usually do not have a pad token by default\n",
        "if base_tokenizer.pad_token is None:\n",
        "    base_tokenizer.pad_token = base_tokenizer.eos_token\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    quantization_config=bnb_config,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAfePBtFqK_c",
        "outputId": "aa6a2985-9aea-4096-ead9-ffb041a399da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4472\n",
            "2173\n",
            "2588\n",
            "3493\n",
            "1333\n",
            "7101\n",
            "3200\n",
            "2747\n",
            "3450\n",
            "2684\n",
            "2382\n",
            "5195\n",
            "3245\n",
            "2329\n",
            "3437\n",
            "1777\n",
            "3072\n",
            "1929\n",
            "2397\n",
            "3252\n",
            "2971\n",
            "3297\n",
            "2854\n",
            "2745\n",
            "2402\n",
            "3726\n",
            "1992\n",
            "2768\n",
            "1412\n",
            "3116\n",
            "3023\n",
            "2304\n",
            "5197\n",
            "3501\n",
            "3816\n",
            "2858\n",
            "2933\n",
            "1648\n",
            "2644\n",
            "3583\n",
            "3513\n",
            "2842\n",
            "2248\n",
            "2041\n",
            "2094\n",
            "1816\n",
            "4051\n",
            "1813\n",
            "2608\n",
            "3987\n"
          ]
        }
      ],
      "source": [
        "base_model.eval()\n",
        "base_outputs = []\n",
        "for base_msg in base_generation_inputs:\n",
        "    prompt = base_tokenizer.apply_chat_template(\n",
        "        base_msg[\"messages\"],\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    inputs = base_tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=base_tokenizer.model_max_length,\n",
        "    ).to(base_model.device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = base_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=10_000,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "            eos_token_id=base_tokenizer.eos_token_id,\n",
        "            pad_token_id=base_tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    response = base_tokenizer.decode(\n",
        "        output[0][inputs[\"input_ids\"].shape[-1]:],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    base_outputs.append((base_msg, response))\n",
        "    print(len(response))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fcrsh3S7tWfK"
      },
      "outputs": [],
      "source": [
        "len(base_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aS2flugWtWUL"
      },
      "outputs": [],
      "source": [
        "Path(\"base_outputs.json\").write_text(json.dumps(base_outputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAThiTv7tV-K"
      },
      "outputs": [],
      "source": [
        "del base_model\n",
        "del base_tokenizer\n",
        "collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b0N_yJYVuIJ6"
      },
      "outputs": [],
      "source": [
        "ADAPTER_PATH = \"./llama3.2-3b-qlora-summary\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_C6Axpem6u-9"
      },
      "outputs": [],
      "source": [
        "def split_msgs(_msg):\n",
        "    messages = _msg[\"messages\"]\n",
        "    return {\n",
        "        \"messages\": messages[: 2]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uEjUfcyr6nd3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 101/101 [00:00<00:00, 7103.39 examples/s]\n"
          ]
        }
      ],
      "source": [
        "generation_inputs = val_dataset.map(split_msgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lsD3ZcnutQXs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 2 files: 100%|██████████| 2/2 [02:07<00:00, 63.88s/it] \n",
            "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.91s/it]\n"
          ]
        }
      ],
      "source": [
        "cs_tokenizer = AutoTokenizer.from_pretrained(ADAPTER_PATH)\n",
        "\n",
        "\n",
        "cs_tokenizer.pad_token = cs_tokenizer.eos_token\n",
        "\n",
        "cs_tokenizer.padding_side = \"right\"\n",
        "\n",
        "cs_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=bnb_config,  # SAME as original\n",
        ")\n",
        "\n",
        "cs_model = prepare_model_for_kbit_training(cs_model, use_gradient_checkpointing=True)\n",
        "cs_model = PeftModel.from_pretrained(\n",
        "    cs_model,\n",
        "    ADAPTER_PATH,\n",
        "    is_trainable=True   # to continue training\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "n-P0H8Ka6fBD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generating\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thorkildkappel/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mgenerating\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     output = \u001b[43mcs_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcs_tokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcs_tokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mdecoding\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m response = cs_tokenizer.decode(\n\u001b[32m     33\u001b[39m     output[\u001b[32m0\u001b[39m][inputs[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[-\u001b[32m1\u001b[39m]:],\n\u001b[32m     34\u001b[39m     skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     35\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/peft/peft_model.py:2048\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   2046\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   2047\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m2048\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2049\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2050\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/transformers/generation/utils.py:2564\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2561\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2563\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2576\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2577\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2579\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/transformers/generation/utils.py:2784\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2781\u001b[39m model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(input_ids, **model_kwargs)\n\u001b[32m   2783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m2784\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2785\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2786\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:918\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    920\u001b[39m     output = output.to_tuple()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py:459\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    440\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    441\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    442\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    443\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    444\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:1072\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1069\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1074\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1075\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1076\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1077\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py:395\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[39m\n\u001b[32m    392\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    407\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    408\u001b[39m     past_key_values=past_key_values,\n\u001b[32m    409\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py:309\u001b[39m, in \u001b[36mLlamaDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m residual = hidden_states\n\u001b[32m    308\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py:155\u001b[39m, in \u001b[36mLlamaMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     down_proj = \u001b[38;5;28mself\u001b[39m.down_proj(\u001b[38;5;28mself\u001b[39m.act_fn(\u001b[38;5;28mself\u001b[39m.gate_proj(x)) * \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/peft/tuners/lora/bnb.py:262\u001b[39m, in \u001b[36mLinear8bitLt.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    260\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.base_layer(x, *args, **kwargs)\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m active_adapter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.active_adapters:\n\u001b[32m    264\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m active_adapter \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lora_A.keys():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/bitsandbytes/nn/modules.py:1094\u001b[39m, in \u001b[36mLinear8bitLt.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias.dtype != x.dtype:\n\u001b[32m   1092\u001b[39m     \u001b[38;5;28mself\u001b[39m.bias.data = \u001b[38;5;28mself\u001b[39m.bias.data.to(x.dtype)\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m out = \u001b[43mbnb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.has_fp16_weights \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.CB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1097\u001b[39m     \u001b[38;5;28mself\u001b[39m.weight.data = \u001b[38;5;28mself\u001b[39m.state.CB\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/bitsandbytes/autograd/_functions.py:366\u001b[39m, in \u001b[36mmatmul\u001b[39m\u001b[34m(A, B, out, state, threshold, bias)\u001b[39m\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m A.device.type \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mxpu\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    365\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m MatMul8bitFp.apply(A, B, out, bias, state)\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMatMul8bitLt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/autograd/function.py:581\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    579\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    580\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    584\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    586\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    587\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    588\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    589\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/bitsandbytes/autograd/_functions.py:134\u001b[39m, in \u001b[36mMatMul8bitLt.forward\u001b[39m\u001b[34m(ctx, A, B, out, bias, state)\u001b[39m\n\u001b[32m    131\u001b[39m     CA, CAt, SCA, SCAt, outlier_cols = F.int8_double_quant(A.to(torch.float16), threshold=state.threshold)\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# Fast path\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     CA, SCA, outlier_cols = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint8_vectorwise_quant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat16\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     CAt = SCAt = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    137\u001b[39m has_grad = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/bitsandbytes/functional.py:1962\u001b[39m, in \u001b[36mint8_vectorwise_quant\u001b[39m\u001b[34m(A, threshold)\u001b[39m\n\u001b[32m   1944\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mint8_vectorwise_quant\u001b[39m(A: torch.Tensor, threshold=\u001b[32m0.0\u001b[39m):\n\u001b[32m   1945\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Quantizes a tensor with dtype `torch.float16` to `torch.int8` in accordance to the `LLM.int8()` algorithm.\u001b[39;00m\n\u001b[32m   1946\u001b[39m \n\u001b[32m   1947\u001b[39m \u001b[33;03m    For more information, see the [LLM.int8() paper](https://arxiv.org/abs/2208.07339).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1960\u001b[39m \u001b[33;03m        - `torch.Tensor` with dtype `torch.int32`, *optional*: A list of column indices which contain outlier features.\u001b[39;00m\n\u001b[32m   1961\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1962\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbitsandbytes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint8_vectorwise_quant\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/_ops.py:841\u001b[39m, in \u001b[36mOpOverload.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/_compile.py:53\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     50\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     51\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py:1044\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1042\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m   1043\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1046\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/torch/library.py:732\u001b[39m, in \u001b[36m_impl.<locals>.register_.<locals>.func_no_dynamo\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;129m@torch\u001b[39m._disable_dynamo\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunc_no_dynamo\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/7. sem/NLP /project/NLP_project_group6/.venv/lib/python3.13/site-packages/bitsandbytes/backends/default/ops.py:152\u001b[39m, in \u001b[36m_\u001b[39m\u001b[34m(A, threshold)\u001b[39m\n\u001b[32m    146\u001b[39m outliers = A.abs() >= threshold\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m outliers.any():\n\u001b[32m    149\u001b[39m     \u001b[38;5;66;03m# Determine which columns contain outliers, and zero out the\u001b[39;00m\n\u001b[32m    150\u001b[39m     \u001b[38;5;66;03m# outliers ahead of quantization. We need to keep a backup of these\u001b[39;00m\n\u001b[32m    151\u001b[39m     \u001b[38;5;66;03m# outliers to restore them after quantization.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     outlier_cols = torch.argwhere(\u001b[43moutliers\u001b[49m\u001b[43m.\u001b[49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m).view(-\u001b[32m1\u001b[39m)\n\u001b[32m    153\u001b[39m     outlier_restore = A[outliers].clone()\n\u001b[32m    154\u001b[39m     A[outliers] = \u001b[32m0\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "cs_model.eval()\n",
        "cs_outputs = []\n",
        "total = len(generation_inputs)\n",
        "for index, cs_msg in enumerate(generation_inputs):\n",
        "    prompt = cs_tokenizer.apply_chat_template(\n",
        "        cs_msg[\"messages\"],\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    inputs = cs_tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=cs_tokenizer.model_max_length,\n",
        "    ).to(cs_model.device)\n",
        "\n",
        "    print(\"generating\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = cs_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=50,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "            eos_token_id=cs_tokenizer.eos_token_id,\n",
        "            pad_token_id=cs_tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    print(\"decoding\")\n",
        "    response = cs_tokenizer.decode(\n",
        "        output[0][inputs[\"input_ids\"].shape[-1]:],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    cs_outputs.append((cs_msg, response))\n",
        "    print(f\"{((index + 1) / total) * 100}% - {len(response)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(cs_outputs, columns=['cs_msg', 'response'])\n",
        "\n",
        "df.to_csv()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "055d3b192def41ccace818bc2c8b2684": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06365b5aafda4a61806d483de923ca4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06c526461b3c439d81e9f4b1a67bef89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd68af5b3a1a4cd2a3d2e51831eb1e3f",
            "placeholder": "​",
            "style": "IPY_MODEL_3f14f6a5af6d45a5981d24df424ee151",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "0795e6dc22c94d958541354b9eb211ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06365b5aafda4a61806d483de923ca4a",
            "placeholder": "​",
            "style": "IPY_MODEL_10debec83cbe443b9b5e778ebb06bc27",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 20.3MB/s]"
          }
        },
        "08428c6e4d104fd08ea762af7b347b49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0855ac647c51420897207bd9837d2298": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b5ebf399f624b13b15de735887a015e",
            "placeholder": "​",
            "style": "IPY_MODEL_c0d352944469475cbde6f3555e6c6277",
            "value": " 878/878 [00:00&lt;00:00, 122kB/s]"
          }
        },
        "09202c003d074ef2b985902c8690391b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a245a2bc5014dd5a0e0fbdce4c61dce",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_827ac0be3728424582e83e2fc1d31008",
            "value": 2
          }
        },
        "0cd4870d05b74647ab36181be56729c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1417a3ea7b9417e8480570e360f9f48",
            "placeholder": "​",
            "style": "IPY_MODEL_300d1300846b485990a3538d4fa456fc",
            "value": "tokenizer.json: 100%"
          }
        },
        "0d3cdca63fa5417e8a2cefdc809b4c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f4a154bf65e4b59a5e369083df2cef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10debec83cbe443b9b5e778ebb06bc27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1101c414c8a54e2d99cf491599c853d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1301f17e37da4320aac7917c9553756e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d3c690292c940ea805e27ec9943df59",
            "placeholder": "​",
            "style": "IPY_MODEL_da3e442144c947508cbb7c2d2993500b",
            "value": " 2/2 [00:06&lt;00:00,  3.16s/it]"
          }
        },
        "13ea083a6c5d45c891984a0a73759a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14ff1e39878c4a0a902aaa7ba15be878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06c526461b3c439d81e9f4b1a67bef89",
              "IPY_MODEL_4d00c63398a3496e9faa2246b2c32541",
              "IPY_MODEL_78b2b4581bc940348ba1f0b21a997b77"
            ],
            "layout": "IPY_MODEL_eb57fc4b0be1401abc7d6867a6849795"
          }
        },
        "152e939ee063490aa640feb59eddb545": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_336350b3227a4fb6b5678950ae02308a",
            "max": 1459729952,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61d6cce34867420098b1888865ccdac4",
            "value": 1459729952
          }
        },
        "1c64423283e14d3d8b0aba94f70415ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dd9be2b4ad44655b138ea0ee6a78027": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f845e30f64e4d7ea65fa8caf2f892d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "225efe0dc6dc4e69a22903abafe3afd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "229f9bac145e432eac3dcc9e0baa5d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb48d8dca3b4f8baa6a181f599af4c6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e4a6aa9039741f698e46cdfe287a16e",
            "value": 2
          }
        },
        "28de7fa0443647d39b3f9a6712f53a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f060c6ab72b44daa864e3f1e2fbeda9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f5ad3b92e2442f3a6ddd53cb1be1893": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fd49de4d17841f28842856ba878d3c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eea3a7d14544be8b5dbdb255dedbded",
            "placeholder": "​",
            "style": "IPY_MODEL_eae485e90e94418c9703bbae5cff6d95",
            "value": " 2/2 [00:18&lt;00:00, 18.38s/it]"
          }
        },
        "300d1300846b485990a3538d4fa456fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32329bf24cbe4181aa4a8a21182c48d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaafdbfb57ed46d5992cd2939131b274",
            "placeholder": "​",
            "style": "IPY_MODEL_71c710b347794ab48e9d57e0ef6fdef1",
            "value": " 54.5k/54.5k [00:00&lt;00:00, 6.74MB/s]"
          }
        },
        "336350b3227a4fb6b5678950ae02308a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3771e7d855f64f7f94fd961f55716d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bb8a9ed4dae48f295102a600bb65e9a",
            "placeholder": "​",
            "style": "IPY_MODEL_5776ddb2ba1748b5be5347476e73c5cf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3792c7d80cd042caa861237e5a5a7f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "393ad97c931e449a91e104e85783fe66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f845e30f64e4d7ea65fa8caf2f892d5",
            "placeholder": "​",
            "style": "IPY_MODEL_1c64423283e14d3d8b0aba94f70415ba",
            "value": "config.json: 100%"
          }
        },
        "3bb8a9ed4dae48f295102a600bb65e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c51563cf9b7417f96660494a64abfa0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f14f6a5af6d45a5981d24df424ee151": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "428dfe8a63ea4fa387f753e38ad013a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a56280bccfc4776a2e83a6308034eeb",
              "IPY_MODEL_229f9bac145e432eac3dcc9e0baa5d28",
              "IPY_MODEL_2fd49de4d17841f28842856ba878d3c5"
            ],
            "layout": "IPY_MODEL_444c25a1af534fda89afbe56c392ca56"
          }
        },
        "438ff1b810f743b4b9656f84c5cc5914": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "444c25a1af534fda89afbe56c392ca56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "490465d310a849479efb022b418c9c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b59e7a392ca14ec8a4a88839c98e95db",
            "max": 54528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_682c4817bc91424a969c7cfda695f543",
            "value": 54528
          }
        },
        "4c37f59d45a7487aa0ce3c8fbe6ac038": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c54b01ebe8c407ab992310df2895176": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c9cb58826364bc58c0bc7fb9a34af9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d00c63398a3496e9faa2246b2c32541": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2ebd9f83bc44ba5ad6dc02626bf3e6f",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d3cdca63fa5417e8a2cefdc809b4c3e",
            "value": 296
          }
        },
        "4eea3a7d14544be8b5dbdb255dedbded": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ff8bbe0699749ec9aa91f9a8a0f0032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50ba1f15232d465facd6e3f43a6626cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c37f59d45a7487aa0ce3c8fbe6ac038",
            "placeholder": "​",
            "style": "IPY_MODEL_225efe0dc6dc4e69a22903abafe3afd8",
            "value": " 20.9k/20.9k [00:00&lt;00:00, 2.55MB/s]"
          }
        },
        "5776ddb2ba1748b5be5347476e73c5cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59dbf2b961c44edfbae4256d83bb1708": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cea44ec8331a4058bceef660bf396cf8",
              "IPY_MODEL_152e939ee063490aa640feb59eddb545",
              "IPY_MODEL_677966dddd8b4096a0b7251366fae938"
            ],
            "layout": "IPY_MODEL_ed5a780960de43ec80a46344e722b35c"
          }
        },
        "5a245a2bc5014dd5a0e0fbdce4c61dce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5de3b4d0027c4b57aafcab69eff64218": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_858b1a1e25174b8398cf1f7def4c74e0",
              "IPY_MODEL_a776a2d4181e46a693da3d7367e8baf6",
              "IPY_MODEL_bc36d005b7584ca2acee5be5ffb2cef3"
            ],
            "layout": "IPY_MODEL_08428c6e4d104fd08ea762af7b347b49"
          }
        },
        "5e4a6aa9039741f698e46cdfe287a16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ec8c8c2b368402fa1cf6b8537436a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f2461130b4a4469bc5f19c6a0d772b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60cdf53a72304a458ae66faed8b3d4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3771e7d855f64f7f94fd961f55716d26",
              "IPY_MODEL_490465d310a849479efb022b418c9c93",
              "IPY_MODEL_32329bf24cbe4181aa4a8a21182c48d5"
            ],
            "layout": "IPY_MODEL_1101c414c8a54e2d99cf491599c853d8"
          }
        },
        "61d6cce34867420098b1888865ccdac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6255e3b5877749289017ab00a9202319": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6492b6fb63e4484c9adee33ddb75ec71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0b005a41da34a11829f12ab9e1ebe5b",
            "placeholder": "​",
            "style": "IPY_MODEL_4c54b01ebe8c407ab992310df2895176",
            "value": "Map: 100%"
          }
        },
        "677966dddd8b4096a0b7251366fae938": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a72bb69172374850a5eb4450f3ac9f99",
            "placeholder": "​",
            "style": "IPY_MODEL_055d3b192def41ccace818bc2c8b2684",
            "value": " 1.46G/1.46G [00:09&lt;00:00, 88.4MB/s]"
          }
        },
        "682c4817bc91424a969c7cfda695f543": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c3c63491bf8448abece39eb428a52f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d79c59696da4eb290e5febcaadfcb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3031da0e4574822a1d45dedb927ce67",
            "max": 878,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff9fe16a51934b2b9fc50fafbbad9ce1",
            "value": 878
          }
        },
        "6eb48d8dca3b4f8baa6a181f599af4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef970331a554a519e42d46522fefdb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70efee92eccf4f63b11acc9200f8351d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fca4bdd0991c4adca567d768c46f5ca7",
            "placeholder": "​",
            "style": "IPY_MODEL_eac6e7a4232c464cbd251a37aeecaa72",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "71c710b347794ab48e9d57e0ef6fdef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7371ba4c17b948d6859a89e899050601": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738a193bfd99452a874eeb1a910569b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77abae2bf7bd4d7999094ee2c5fc4e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f2461130b4a4469bc5f19c6a0d772b1",
            "placeholder": "​",
            "style": "IPY_MODEL_bf165ae12dcb4b5992a0c3419a0ae230",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "78b2b4581bc940348ba1f0b21a997b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7371ba4c17b948d6859a89e899050601",
            "placeholder": "​",
            "style": "IPY_MODEL_3792c7d80cd042caa861237e5a5a7f88",
            "value": " 296/296 [00:00&lt;00:00, 39.4kB/s]"
          }
        },
        "7a56280bccfc4776a2e83a6308034eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83780244380c4b5abfe605e4a7389a23",
            "placeholder": "​",
            "style": "IPY_MODEL_438ff1b810f743b4b9656f84c5cc5914",
            "value": "Fetching 2 files: 100%"
          }
        },
        "7a88f81d22d3448f852f6d9f6cf74348": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e3dc80f38fe4b9e90c56633eceed6f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80ef48534d264ba897dc320d92aef3e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_738a193bfd99452a874eeb1a910569b6",
            "max": 189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ec8c8c2b368402fa1cf6b8537436a77",
            "value": 189
          }
        },
        "827ac0be3728424582e83e2fc1d31008": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83780244380c4b5abfe605e4a7389a23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "858b1a1e25174b8398cf1f7def4c74e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef970331a554a519e42d46522fefdb7",
            "placeholder": "​",
            "style": "IPY_MODEL_2f5ad3b92e2442f3a6ddd53cb1be1893",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "98fa080856bb49ff86039b70465aab14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cd4870d05b74647ab36181be56729c3",
              "IPY_MODEL_bf5a481b37854f64aeab6ca042a94da4",
              "IPY_MODEL_0795e6dc22c94d958541354b9eb211ad"
            ],
            "layout": "IPY_MODEL_bc0c72356941423f8bbf0056a948938c"
          }
        },
        "9b5ebf399f624b13b15de735887a015e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d3c690292c940ea805e27ec9943df59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2fa305397f94b2db05f1cfc254c913d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6492b6fb63e4484c9adee33ddb75ec71",
              "IPY_MODEL_f5ed6a170fac437f9232c30375ecba13",
              "IPY_MODEL_a681a02a089a4f31bf5e78d308f38002"
            ],
            "layout": "IPY_MODEL_3c51563cf9b7417f96660494a64abfa0"
          }
        },
        "a38a3c44c26747df8f54020a4c32eaf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a681a02a089a4f31bf5e78d308f38002": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcc20ff8befa426387a4a2c59a0169a7",
            "placeholder": "​",
            "style": "IPY_MODEL_0f4a154bf65e4b59a5e369083df2cef5",
            "value": " 101/101 [00:00&lt;00:00, 2698.61 examples/s]"
          }
        },
        "a71a6564eef34ef39242065500f89c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a72bb69172374850a5eb4450f3ac9f99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a776a2d4181e46a693da3d7367e8baf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3276a231d324137a409a35908de7024",
            "max": 4965799096,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab32170ca7c74c048c724f3a80bf9a8c",
            "value": 4965799096
          }
        },
        "aaafdbfb57ed46d5992cd2939131b274": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab32170ca7c74c048c724f3a80bf9a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aba419aeb82b467c88780412a300cfba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c3c63491bf8448abece39eb428a52f0",
            "placeholder": "​",
            "style": "IPY_MODEL_1dd9be2b4ad44655b138ea0ee6a78027",
            "value": " 189/189 [00:00&lt;00:00, 24.7kB/s]"
          }
        },
        "ad47f594d4b74a96ac783e88dad964b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc238511f564740a0f1788d107a4d94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae3eb50f0ebf455e9b76b33d6692c207": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1417a3ea7b9417e8480570e360f9f48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4ace38457ec484fa10b0e62e5baa84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f060c6ab72b44daa864e3f1e2fbeda9",
            "placeholder": "​",
            "style": "IPY_MODEL_ae3eb50f0ebf455e9b76b33d6692c207",
            "value": "generation_config.json: 100%"
          }
        },
        "b59e7a392ca14ec8a4a88839c98e95db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc0c72356941423f8bbf0056a948938c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc36d005b7584ca2acee5be5ffb2cef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c86207436901472986282893210c173c",
            "placeholder": "​",
            "style": "IPY_MODEL_bff9f53bef434e8488917d18f42680f3",
            "value": " 4.97G/4.97G [00:17&lt;00:00, 306MB/s]"
          }
        },
        "bf165ae12dcb4b5992a0c3419a0ae230": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf5a481b37854f64aeab6ca042a94da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adc238511f564740a0f1788d107a4d94",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6255e3b5877749289017ab00a9202319",
            "value": 9085657
          }
        },
        "bff9f53bef434e8488917d18f42680f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0d352944469475cbde6f3555e6c6277": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3031da0e4574822a1d45dedb927ce67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3276a231d324137a409a35908de7024": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c90a495abf46028ec72e9954541815": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4ace38457ec484fa10b0e62e5baa84f",
              "IPY_MODEL_80ef48534d264ba897dc320d92aef3e9",
              "IPY_MODEL_aba419aeb82b467c88780412a300cfba"
            ],
            "layout": "IPY_MODEL_7a88f81d22d3448f852f6d9f6cf74348"
          }
        },
        "c86207436901472986282893210c173c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea44ec8331a4058bceef660bf396cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a38a3c44c26747df8f54020a4c32eaf5",
            "placeholder": "​",
            "style": "IPY_MODEL_4ff8bbe0699749ec9aa91f9a8a0f0032",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "d901177d164e400aaf61467de19ca671": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a34773567a451889503283f50f39e1",
            "max": 20919,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a71a6564eef34ef39242065500f89c4f",
            "value": 20919
          }
        },
        "da3e442144c947508cbb7c2d2993500b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcc20ff8befa426387a4a2c59a0169a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd68af5b3a1a4cd2a3d2e51831eb1e3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ebd9f83bc44ba5ad6dc02626bf3e6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4367ad58be841148987f12b964a32f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_393ad97c931e449a91e104e85783fe66",
              "IPY_MODEL_6d79c59696da4eb290e5febcaadfcb66",
              "IPY_MODEL_0855ac647c51420897207bd9837d2298"
            ],
            "layout": "IPY_MODEL_7e3dc80f38fe4b9e90c56633eceed6f2"
          }
        },
        "e448d97be72b4f16b49946e373097222": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70efee92eccf4f63b11acc9200f8351d",
              "IPY_MODEL_09202c003d074ef2b985902c8690391b",
              "IPY_MODEL_1301f17e37da4320aac7917c9553756e"
            ],
            "layout": "IPY_MODEL_28de7fa0443647d39b3f9a6712f53a1e"
          }
        },
        "e7a34773567a451889503283f50f39e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eac6e7a4232c464cbd251a37aeecaa72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eae485e90e94418c9703bbae5cff6d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb57fc4b0be1401abc7d6867a6849795": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed5a780960de43ec80a46344e722b35c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0b005a41da34a11829f12ab9e1ebe5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5ed6a170fac437f9232c30375ecba13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad47f594d4b74a96ac783e88dad964b9",
            "max": 101,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13ea083a6c5d45c891984a0a73759a6d",
            "value": 101
          }
        },
        "fb0d6d199b124f02b4254e22c4b73f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77abae2bf7bd4d7999094ee2c5fc4e67",
              "IPY_MODEL_d901177d164e400aaf61467de19ca671",
              "IPY_MODEL_50ba1f15232d465facd6e3f43a6626cf"
            ],
            "layout": "IPY_MODEL_4c9cb58826364bc58c0bc7fb9a34af9d"
          }
        },
        "fca4bdd0991c4adca567d768c46f5ca7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff9fe16a51934b2b9fc50fafbbad9ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
