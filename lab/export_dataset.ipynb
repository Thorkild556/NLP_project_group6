{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e0c8dcd36c726ae",
   "metadata": {},
   "source": [
    "# AIM\n",
    "\n",
    "Aim of this Notebook is to export the TL;DR and custom dataset to jsonl file so we can upload it in the colab and then use it for our finetuning and evalution\n",
    "\n",
    "\n",
    "## Exporting the Custom Dataset\n",
    "\n",
    "Custom Dataset is the dataset we collected from YouTube videos, where we asked youtube with a search query and collected the transcripts of the top 4 possible videos. and then for each search query we asked the gpt 5.1 chat to summarize the transcripts into a concise summary.\n",
    "\n",
    "you can find how we fetched the youtube data from here: [fetch_transcript_dataset.py](https://github.com/au-nlp/project-milestone-p2-group-6/blob/main/src/fetch_transcript_dataset.py)\n",
    "and how we prompted gpt 5.1 chat from here: [summary_for_custom_dataset.py](https://github.com/au-nlp/project-milestone-p2-group-6/blob/main/src/summary_for_custom_dataset.py)\n",
    "\n",
    "\n",
    "we would now be exporting them to jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T11:40:24.446861400Z",
     "start_time": "2025-12-19T11:40:24.434496Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "project_root = Path.cwd().parent  # or Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "# we are doing this so we can import src folder\n",
    "\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlite3 import connect\n",
    "from datasets import load_dataset\n",
    "from src.utils.batch_utils import data_folder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from src.load_dataset import CS_JSON, TL_DR_JSON\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b8ca27bc1cc46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T11:40:24.464942400Z",
     "start_time": "2025-12-19T11:40:24.449439500Z"
    }
   },
   "outputs": [],
   "source": "db = data_folder / \"saved_videos.db\""
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf0f0023313843e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T11:40:24.484648800Z",
     "start_time": "2025-12-19T11:40:24.467951500Z"
    }
   },
   "outputs": [],
   "source": [
    "db_conn = connect(str(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc24ff6bae6cfd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T11:40:25.354716500Z",
     "start_time": "2025-12-19T11:40:24.486675100Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_results = pd.read_sql(\"SELECT * FROM PromptResults where Response is NOT NULL\", db_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd89b9c90c368cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T11:40:25.379046900Z",
     "start_time": "2025-12-19T11:40:25.358151900Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = []\n",
    "SYSTEM_PROMPT = \"You summarize multiple video transcripts into concise, factual summaries.\"\n",
    "\n",
    "for row in prompt_results[[\"AgentPrompt\", \"Response\"]].itertuples(index=False):\n",
    "    samples.append({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": row[0]},\n",
    "            {\"role\": \"assistant\", \"content\": row[1]},\n",
    "        ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2fe6063119fe0e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T11:40:25.734885Z",
     "start_time": "2025-12-19T11:40:25.380140Z"
    }
   },
   "outputs": [],
   "source": "pd.DataFrame(samples).to_json(data_folder / CS_JSON, orient='records', lines=True)"
  },
  {
   "cell_type": "markdown",
   "id": "ad5d5dd9a152ec6c",
   "metadata": {},
   "source": [
    "## Exporting the TL;DR Dataset\n",
    "\n",
    "After Loading [TL;DR Dataset](https://huggingface.co/datasets/trl-lib/tldr), we would be first clustering the dataset based on the similarity of the post contents and then concating their tl;dr to form a dataset that's similar to our custom dataset.\n",
    "\n",
    "Once done we would export it to jsonl file\n",
    "\n",
    "but first we would preprocess the tl;dr dataset and then proceed with clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "924c10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = load_dataset(\"trl-lib/tldr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa557d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = {}\n",
    "# we would be using regex to extract the post content and title and subreddit\n",
    "for set_type in data_set.keys():\n",
    "  ds[set_type] = pd.DataFrame(data_set[set_type])\n",
    "  ds[set_type][\"prompt_post\"] = ds[set_type].prompt.str.extract(\n",
    "      r'POST: ((.|\\n)*)\\nTL;DR:', expand=False\n",
    "  ).iloc[:, 0]\n",
    "  ds[set_type][\"prompt_title\"] = ds[set_type].prompt.str.extract(\n",
    "    r'TITLE: ((.|\\n)*)\\n\\nPOST:', expand=False\n",
    "  ).iloc[:, 0]\n",
    "  ds[set_type][\"subreddit\"] = ds[set_type].prompt.str.extract(\n",
    "    r'SUBREDDIT: ((.|\\n)*)\\n\\nTITLE:', expand=False\n",
    "  ).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd488919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['prompt', 'completion', 'prompt_post', 'prompt_title', 'subreddit'], dtype='object')\n",
      "My 25 year old son has a job which means he does 12 hour nightshifts 3-4 times a week, including weekends. After his nightshifts, he comes to my house an sleeps in the spare bedroom. He sleeps in my house because he says at his own house, it's too noisy. \n",
      "\n",
      "In his own house, he has his partner, who is mostly home during weekdays as she only works weekends. They then have a one year old, then his partner has a 14 year old girl who - if it's the weekends or after school, always has at least 2 friends with her. It's the group of girls who are the noisiest. So the house is very noisy. \n",
      "\n",
      "I don't have a problem with my son sleeping in my spare room, but I think as his mother I should try and encourage him to have a better arrangement set up in his own home so he can sleep there, for his sake. For example, if the 14 year old does have friends over, she could only have them downstairs, and they'd not be allowed upstairs when my son is sleeping. My son's partner says since the 14 year old's bedroom is upstairs she doesnt think she could tell her daughter and her friends they couldnt come upstairs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set = ds[\"train\"]\n",
    "\n",
    "# we are removing the word TL;DR from the post\n",
    "train_set[\"prompt_post\"] = train_set[\"prompt_post\"].str.replace(r'\\s*TL;DR:\\s*', '', regex=True)\n",
    "\n",
    "# remove leading spaces and tabs from the beginning of the text and also from the start of each new line\n",
    "train_set[\"completion\"] = [\n",
    "    re.sub(r'\\n[ \\t]+', '\\n', re.sub(r'^[ \\t]+', '', t))\n",
    "    for t in train_set[\"completion\"]\n",
    "]\n",
    "print(train_set.columns)\n",
    "print(train_set.iloc[1234][\"prompt_post\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0675a235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/ipykernel_8676/1256756349.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  downsampled_other = other_df.groupby('subreddit', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# Separate AskReddit from other subreddits\n",
    "askreddit_df = train_set[train_set['subreddit'] == 'r/AskReddit']\n",
    "other_df = train_set[train_set['subreddit'] != 'r/AskReddit']\n",
    "\n",
    "# Downsample other subreddits to max 2000 each\n",
    "downsampled_other = other_df.groupby('subreddit', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=min(len(x), 2000), random_state=42)\n",
    ")\n",
    "\n",
    "# Combine back together\n",
    "train_set = pd.concat([askreddit_df, downsampled_other], ignore_index=True)\n",
    "train_set = train_set.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "# print(train_set['subreddit'].value_counts())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Note\n",
    "\n",
    "we are removing duplicate posts from the dataset, we have observed the duplicate posts (same post) posted in multiple subreddits"
   ],
   "id": "81cfc6f876ce6194"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a268985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41773\n",
      "41601\n"
     ]
    }
   ],
   "source": [
    "# before dropping\n",
    "print(len(train_set))\n",
    "\n",
    "train_set = train_set.drop_duplicates([\"prompt_post\"])\n",
    "\n",
    "# after dropping duplicates\n",
    "print(len(train_set))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Clustering\n",
    "\n",
    "we would be clustering the posts using cosine similarity"
   ],
   "id": "a423f380aaec9da4"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a981f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41601, 62384)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "# converting the posts to TF-IDF Matrix\n",
    "tfidf_mat = tfidf.fit_transform(train_set[\"prompt_post\"])\n",
    "print(tfidf_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "479edb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any size-1 clusters? False\n",
      "Clustered: 20487 / 41601\n",
      "Unassigned: 21114\n"
     ]
    }
   ],
   "source": [
    "# clustering algo. for posts\n",
    "def knn_greedy_clustering(tfidf_matrix, min_size=2, max_size=4, \n",
    "                         threshold=0.7, n_neighbors=20):\n",
    "    \"\"\"\n",
    "    Use k-NN for fast neighbor finding, then greedy cluster formation\n",
    "    \"\"\"\n",
    "    n = tfidf_matrix.shape[0]\n",
    "    \n",
    "    # Fit k-NN model (cosine similarity)\n",
    "    nbrs = NearestNeighbors(n_neighbors=min(n_neighbors + 1, n),  # +1 for self\n",
    "                           metric='cosine', \n",
    "                           algorithm='auto')\n",
    "    nbrs.fit(tfidf_matrix)\n",
    "    \n",
    "    # Get neighbors for all samples at once\n",
    "    distances, indices = nbrs.kneighbors(tfidf_matrix)\n",
    "    similarities = 1 - distances  # Convert distance to similarity\n",
    "    \n",
    "    # Greedy clustering using precomputed neighbors\n",
    "    assigned = np.zeros(n, dtype=bool)\n",
    "    clusters = []\n",
    "    \n",
    "    # Process in order of maximum similarity (samples with strong matches first)\n",
    "    max_sims = similarities[:, 1].copy()  # Skip self (index 0)\n",
    "    order = np.argsort(max_sims)[::-1]\n",
    "    \n",
    "    for idx in order:\n",
    "        if assigned[idx]:\n",
    "            continue\n",
    "        \n",
    "        cluster = [int(idx)]  # Convert to Python int immediately\n",
    "        \n",
    "        # Add neighbors that are unassigned and above threshold\n",
    "        # Start from index 1 to skip self (index 0 is always the sample itself)\n",
    "        for neighbor_idx, sim in zip(indices[idx][1:], similarities[idx][1:]):\n",
    "            neighbor_idx = int(neighbor_idx)  # Convert to Python int\n",
    "\n",
    "            # if the post's similarity is above 95% we are discarding them\n",
    "            # since they might be from the same ones but across subreddits\n",
    "            if neighbor_idx != idx and not assigned[neighbor_idx] and sim >= threshold and sim <0.95:\n",
    "                cluster.append(neighbor_idx)\n",
    "                if len(cluster) >= max_size:\n",
    "                    break\n",
    "        \n",
    "        # Only add cluster if it meets minimum size\n",
    "        if len(cluster) >= min_size:\n",
    "            clusters.append(cluster)\n",
    "            assigned[cluster] = True\n",
    "        # If cluster too small, leave sample unassigned for now\n",
    "    \n",
    "    return clusters, assigned\n",
    "\n",
    "# Usage\n",
    "clusters, assigned = knn_greedy_clustering(\n",
    "    tfidf_mat, \n",
    "    min_size=2, \n",
    "    max_size=4, \n",
    "    threshold=0.3,\n",
    "    n_neighbors=50\n",
    ")\n",
    "\n",
    "# Verify no single-element clusters\n",
    "print(f\"Any size-1 clusters? {any(len(c) == 1 for c in clusters)}\")\n",
    "print(f\"Clustered: {assigned.sum()} / {len(assigned)}\")\n",
    "print(f\"Unassigned: {(~assigned).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aaf1f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster size distribution:\n",
      "  Size 2: 3121 clusters\n",
      "  Size 3: 1047 clusters\n",
      "  Size 4: 2776 clusters\n"
     ]
    }
   ],
   "source": [
    "cluster_sizes = [len(c) for c in clusters]\n",
    "unique, counts = np.unique(cluster_sizes, return_counts=True)\n",
    "\n",
    "print(\"Cluster size distribution:\")\n",
    "for size, count in zip(unique, counts):\n",
    "    print(f\"  Size {size}: {count} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c89889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38596, 21353, 29682, 16046]\n"
     ]
    }
   ],
   "source": [
    "print(clusters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad53c1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit a careless jaywalker at around 20mph going thru an intersection on my green. I drove abiding all traffic laws. What can be the outcome?\n",
      "2 jobs, the first $65k train driver or $?? IT position with no formal job title yet but he did mention working under him as an admin assistant.\n",
      "I need a new laptop and I might be fed up with Windows. Show me what's best all around without any specific criteria.\n"
     ]
    }
   ],
   "source": [
    "print(train_set['completion'].iloc[36376])\n",
    "#print(train_set['completion'].iloc[34728])\n",
    "print(train_set['completion'].iloc[18913])\n",
    "print(train_set['completion'].iloc[6146])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5d78af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow, there really is a subreddit for everything. Ok well if someone who knows about this could help me out i would appreciate it.\n",
      "\n",
      "I few month ago I heard about how Ireland adopted A.C.T.A ( or was it sopa?) anyway just wile skimming and article I heard that this gave them the right to search mp3 players, ipods, and laptops for pirated music in the same way they can search your bag for drugs. now i didn't pay attention to the credibility of the source at the time because i hadn't seen going to Ireland in the foreseeable future but something has come up and I am headed there this December. If this is true it will mean the difference between be bringing my ipod and laptop or not.\n",
      "\n",
      "I have been doing some research but it is the internet and its difficult to find a credible answer to any obscure question like this.\n",
      "\n",
      "So this guy was my friend in college. I am really good friends with his girlfriend and to make a long story short we betrayed him and we had sex. So she feels really bad about this and regrets it so she tells him that she cheated on him but wants to work things out and he doesn't break up with her.\n",
      "\n",
      "2 months later she finally tells him we had sex and so he tells me he wants to talk. I get on skype and he tells me that he is at my local high school and wants to meet up (he drove 3 hours and skipped work). I tell him that I don't think it was a good idea. I was playing basketball at the time with a bunch of friends and I told him he could come to where I am.\n",
      "\n",
      "He does and goes into the church which is near the basketball court and I go in and he is sitting on a pew opposite and we talk. He keeps asking me if there is anything he should know I told him no. He tells me wrong answer and I ask him what is the right answer. He then beats around the bush talking about if there is anything i want confess yadayada. So I tell him that you already know everything and finally he just tells me he wants to hear me say it.\n",
      "\n",
      "So I told him we had sex, he then stands up and walks over to me and tries to punch me in the face but I block it. He then starts trying to get me on the ground and starts fighting me in the church. I got away and then walked out of the church towards my friends and he gets in his car and leaves.\n",
      "\n",
      "Anyways what the fuck.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_set[\"prompt_post\"].iloc[11304])\n",
    "print(train_set[\"prompt_post\"].iloc[7008])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f00263f",
   "metadata": {},
   "source": [
    "## Prep. the Dataset\n",
    "\n",
    "we would be creating the new dataset based on the clusters and the prepends (we prepared few prepend templates refer them from here: [tldr_prepend.py](https://github.com/au-nlp/project-milestone-p2-group-6/blob/main/src/tldr_prepend.py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3fa5d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go one directory up from notebook location\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent\n",
    "# Add to path\n",
    "sys.path.append(str(project_root))\n",
    "from src.tldr_prepend import Prepends\n",
    "\n",
    "processed = {\"transscript\": [], \"TLDR\": []}\n",
    "prep = Prepends()\n",
    "\n",
    "for i, group in enumerate(clusters):\n",
    "    processed[\"TLDR\"].append(\"\")\n",
    "    processed[\"transscript\"].append(\"\")\n",
    "    for i, text_idx in enumerate(group):\n",
    "        processed[\"TLDR\"][-1] += f\"{prep.get_random_prepend(i+1)}\\n{train_set['completion'].iloc[text_idx]}\\n\\n\"\n",
    "        # format transscripts\n",
    "        processed[\"transscript\"][-1] += f\"TITLE_OF_VIDEO_{i+1}: {train_set['prompt_title'].iloc[text_idx]}\\n\"\n",
    "        processed[\"transscript\"][-1] += f\"TRANSCRIPT_OF_VIDEO_RESULT_{i + 1}: {train_set['prompt_post'].iloc[text_idx]}\\n\"\n",
    "\n",
    "processed_df = pd.DataFrame(processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57206dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6944\n"
     ]
    }
   ],
   "source": [
    "print(len(processed_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a63c5e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE_OF_VIDEO_1: Reddit, My family is being evicted in 22 days, by my uncle who falsely gotten his name on my grandfather's trust/will. We have virtually no money to get a lawyer. What do we do? (More info inside)[X-post from askreddit]\n",
      "TRANSCRIPT_OF_VIDEO_RESULT_1: **I just copy and pasted this out of the Ask-Reddit section, as it was suggested i post here, too**\n",
      "\n",
      "Okay, basically, my uncle had his name put on all of my grandpa's stuff (i.e. Banks, trust, will...etc) because my grandpa is getting old, and its just what people do. Anyways he decided to turn himself into 'God' and sell both the houses his name was on.\n",
      "\n",
      "I know i didn't explain this before, but my grandpa gave my mom this house, and now my uncle's name is on it.\n",
      "So, This is VERY long and hard to explain whats going on, so i'll just sum it up. My uncle got his lawyers** using my grandpa's money** to send us a eviction notice, and after 72 hours, the police will get involved. He already did this to my other uncle, so we know he is going through with it. This guy is insane.\n",
      "\n",
      "So, my question is this: How do we get a lawyer, or represent ourselves in court, when the person that we are suing(?) is basically using our own money to sue us.\n",
      "We already talked to some lawyers, and they estimated it will cost ~$17k and $5k to start. We don't have money to do this, but if we don't, we lose the house.\n",
      "What the hell do we do??\n",
      "\n",
      "TITLE_OF_VIDEO_2: Grandparents take advantage of my parents.\n",
      "TRANSCRIPT_OF_VIDEO_RESULT_2: My grandpa always calls on my dad for help, even though he is the busiest of the entire family. This may seem shallow but, my grandpa is splitting the will equally 6 ways, despite the other 5 people getting 50k+ never doing anything for my grandparents. My grandpa has a daughter come into his life when he was 80 years old, and now she is getting an equal share. Sob story, my parents had plans and now they have to go babysit my grandma, despite there being 5 other people who have nothing going on.\n",
      "\n",
      "I'm asking what should I do about this situation, It's not about the money, my parents just want people to carry some of the load and EARN their share. my relatives all came out of the woodwork after they found out they were in the will(some of my uncles haven't talked to them in 10+ years). is it wrong for this to make me upset?\n",
      "\n",
      "TITLE_OF_VIDEO_3: WA-\"Tenants\" wont leave until evicted, destroying house, need lots of help!\n",
      "TRANSCRIPT_OF_VIDEO_RESULT_3: So, my grandpa has a huge issue. His son married a bad lady, their house burned down so my grandpa took them in to help them, theyve been living there for a couple months constantly fighting. THERE WAS NO WRITTEN RENTAL AGREEMENT. They do not pay rent, they dont clean the house, stuff is now missing and his home is being destroyed. The son and the wife constantly fight, my grandpa has been hit by the wife and she pulled knifes out on them both. The issue is that the son wont tell on the wife my grandpa didnt call the police right away on his son because its his son and he doesnt want to make his life any harder. He told them to leave his house and they came back and said theyre tenants now and they wont leave without being evicted. My grandpa is retired so he doesnt have lots of money to deal with this. \n",
      "\n",
      "There is no written rental agreement. Iv'e researched tenant laws and apparently we have to go through the eviction process which is fine but theyre destroying his house when he isnt there. Can we write out a rental agreement now? They arent paying rent.\n",
      "\n",
      "What are the steps we need to take? We talked to the county and they said that we cant evict them without a rental agreement.\n",
      "\n",
      "TITLE_OF_VIDEO_4: My parents let my drug addict cousin move into their home. When should I tell them that I don't want my future son around my cousin? (Wife Due Nov 1st)\n",
      "TRANSCRIPT_OF_VIDEO_RESULT_4: So I have this cousin on my mothers side who has been in and out of prison as long as I can remember. He's 34 years old and is always in and out of the system for drug related crimes. Sometimes it's possession, sometimes it's dealing, and sometimes it's stealing to get a fix. As far as my knowledge goes he's not really violent but he is very desperate and he has tried many times to get back on his feet only to end up back in his old habits. \n",
      "\n",
      "He most recently got out of prison a year ago. Our uncle ran into him shortly after at the grocery store and my uncle said my cousin was so drugged he didn't even recognize my uncle. My uncle passed away shortly after from lung cancer. My uncle always lived with my grandparents. \n",
      "\n",
      "Well now that my uncle is gone my cousin asked if he could live with my grandparents and they told him no. Well he showed up at their door step begging so they let him stay a few nights. Eventually they kicked him out because they never wanted him there in the first place. \n",
      "\n",
      "So my parents picked him up and brought him to their house to live with them. \n",
      "\n",
      "So here is my issue. My wife is 25 weeks pregnant.  When the baby comes I am not comfortable with my parents having my son alone if my cousin is going to be at the house. My question is if it would be a better idea to bring this up now or wait until the baby arrives? Am I being unreasonable?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(processed_df[\"transscript\"][587])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "32bfd77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6944"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7dd9d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You summarize multiple video transcripts into concise, factual summaries.\"\n",
    "\n",
    "with open(data_folder / TL_DR_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in processed_df.iterrows():\n",
    "        example = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": row[\"transscript\"]},\n",
    "                {\"role\": \"assistant\", \"content\": row[\"TLDR\"]},\n",
    "            ]\n",
    "        }\n",
    "        f.write(json.dumps(example, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* [X] Exported Custom Dataset to `../data/custom_dataset.jsonl`\n",
    "* [X] Exported TL;DR Dataset to `../data/proc_tldr.jsonl`"
   ],
   "id": "293fadd6a4b9bf67"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
